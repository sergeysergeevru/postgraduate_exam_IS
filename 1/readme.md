### 1. Информация, 	сообщение, информационные системы и процессы как объекты информационной безопасности. Основные свойства информации. Мера количества информации. Энтропия. Модели стоимости информации.

**Информация** - сведения о лицах, предметах, фактах, событиях, явлениях и процессах независимо от формы их представления. [ГОСТ Р 50922-96](http://comsec.spb.ru/matherials/gosts/gost50922-96.pdf)

**Информация** - сведения (сообщения, данные) независимо от формы их представления [N 149-ФЗ](https://rg.ru/2006/07/29/informacia-dok.html)

Основные формы проявления информации:
* сведения — запечатленные в организме результаты отражения движения объектов материального мира.
* сообщения — набор знаков, с помощью которых сведения могут быть переданы другому организму и восприняты им.

Исходя из того, что сообщения это набор знаков несущих в себе определенные
сведения, можно считать, что сообщение это результат кодирования сведений.

Таким образом можно выделить следующие свойства сообщения:
* статичность - выбранный набор знаков, представляющих сообщение, не зависит от времени;
* материальность - способность сообщения влиять на органы чувств;
* объективность - сведения, содержащиеся в сообщении не зависят от субъекта принявшего это сообщение;
* уничтожаемость - сообщение возможно уничтожить (это указывает на ограниченную воспроизводимость сообщения);

В теории информации можно выделить следующие направления оценки информации:
* Структурное - направление, затрагивающее собой область кодирования информации.
Тем самым рассматривает вопросы дискретного строения массивов информаци, таким образом главной операцией
данного направления является подсчет страктурных элементов (например используемых символов).
Используется для оценки технических средств, обрабатывающих информацию.
* Статистическое - отвечает на вопрос вероятности возникновения того или иного сообщения.
Применятся в вопросах передачи информации, для оценки пропускной способности каналов связи.
* Семантическое - определяет ценность (целесообразность, существенность) сведений, содержащихся в сообщении.
Данная оценка требуется определения целесообразности пременения тех или иных методов (методологий)
защиты информации.

**Энтропия** (**_H_**) - в теории информации мера хаотичности информации, неопределенность
появления какого-либо символа первичного алфавита.

Свойства энтропии:
* **_H ≥ 0_**, **_H = 0_** в случае если сообщение известно заранее.
* **_H = MAX_** если сообщения равновероятны.

**Аддитивная модель**

Представляет собой метод экспертной оценки, цель которой произвести оценку
каждого компонента в отдельности. Для этого каждому компоненту **_o ∈ O_** объекта
эксперт выставляет определенную оценку (например по 5 шкале) *__m ∈ M_*, где
**_M ⊆ N_** (например **_M = {1,2,3,4,5}_**). Таким образом образуется вектор
относительных ценностей объекта С = (a1,a2, ... an).
Таким образом появляется зная стоимость хотя бы одного компонента объекта можно вычислить
стоимость одного балла, а далее вычислить стоимость всего объекта.
**Анализ риска**
Оценка возможных потерь основывается на уже известных стоимостях компонент
информации, исходя из прогнозирования возможных угроз компонентам информации.
Возможность каждой угрозы оценивается с помощью вероятностных оценок соответствующих
событий: подсчитывается сумма математических ожиданий потерь для каждой из компонент по
распределению возможных угроз.
**Порядковая шкала ценностей**


#### Specifics *
Пусть сообщения это случайные события и источником данных событий
являтся дискретное множество **_X = {x, p(x)}_**, где **x** это сообщения, а
**_p(x)_** вероятность поялвения данного сообщения.
Таким образом **информация _I(x)_** сообщения **_x_**, выбираемого из множества **_X = {x, p(x)}_**
есть величина вычисляемая по формуле: **_I(x)=-log(p(x))_**
Исходя из определения вытекают следующие свойства:
* Неотрицательность  **__I(x)_ ≥ 0**
* Монотонность **_x1,x2 ∈ X и p(x1)  ≤ p(x2) ⇒ I(x1) ≥ I(x2)_**
* Аддитивность **_I(x1,x2....xn) = ∑ I(xi)_**

Энтропией (**_H_**) **_X = {x, p(x)}_** называется величина **_H(X)= - ∑ p(x)∙ log(p(x))_**, где **_x ∈ X_**.
Таким образом энтропию можно интерпретировать как количественную меру априорной неосведомленности
о том, какое из сообщений будет порождено источником.
________________
\* Конспект по материалам Б. Д. Кудряшов Теория информации, СПбГУ НИУ ИТМО



